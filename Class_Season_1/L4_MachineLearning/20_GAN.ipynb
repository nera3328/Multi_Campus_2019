{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./mnist/data/train-images-idx3-ubyte.gz\n",
      "Extracting ./mnist/data/train-labels-idx1-ubyte.gz\n",
      "Extracting ./mnist/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./mnist/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"./mnist/data/\", one_hot=True)\n",
    "X = tf.placeholder(tf.float32, [None, 28 * 28]) # MNIST = 28*28\n",
    "Z = tf.placeholder(tf.float32, [None, 128]) # Noise Dimension = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(noise_z): # 128 -> 256 -> 28*28\n",
    "    G_W1 = tf.Variable(tf.random_normal([128, 256]))\n",
    "    G_b1 = tf.Variable(tf.zeros([256]))\n",
    "    hidden = tf.nn.relu(tf.matmul(noise_z, G_W1) + G_b1)\n",
    "    \n",
    "    G_W2 = tf.Variable(tf.random_normal([256, 28 * 28]))\n",
    "    G_b2 = tf.Variable(tf.zeros([28 * 28]))\n",
    "    output = tf.nn.sigmoid(tf.matmul(hidden, G_W2) + G_b2)\n",
    "    return output, [G_W1, G_b1, G_W2, G_b2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator(inputs): # 28*28 -> 256 -> 1\n",
    "    D_W1 = tf.Variable(tf.random_normal([28 * 28, 128], stddev=0.01)) #확률값으로 나와야 하고, softmax는 이진분류이기 때문에 다른 것 씀 수 \n",
    "    D_b1 = tf.Variable(tf.zeros([128]))\n",
    "    hidden = tf.nn.relu(tf.matmul(inputs, D_W1) + D_b1)\n",
    "    \n",
    "    D_W2 = tf.Variable(tf.random_normal([128, 1], stddev=0.01))\n",
    "    D_b2 = tf.Variable(tf.zeros([1]))\n",
    "    output = tf.nn.sigmoid(tf.matmul(hidden, D_W2) + D_b2) #sigmoid한 hypo( 확률값 )으로 나온다\n",
    "    return output, [D_W1, D_b1, D_W2, D_b2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "G = generator(noise)\n",
    "D(G) = discriminator(G)\n",
    "D(G) => 0~1 사이의 확률값 => D가 G(fake data)를 예측한 결과\n",
    "\n",
    "D(X) = discriminator(X)\n",
    "D(X) => 0~1 사이의 확률값 => D가 X(real data)를 예측한 결과"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "D(G) == 1 : D가 G를 real이라고 예측했다\n",
    "- G 입장 : 나이스! 오차 0으로! \n",
    "- D 입장 : 이런! 오차를 무한대로!\n",
    "  \n",
    "D(G) == 0 : D가 G를 fake라고 예측했다\n",
    "- G 입장 : 이런! 오차를 무한대로!\n",
    "- D 입장 : 나이스! 오차 0으로! \n",
    "\n",
    "D(X) == 1 : D가 X를 real이라고 예측했다\n",
    "- D 입장 : 나이스! 오차 0으로! \n",
    "\n",
    "D(X) == 0 : D가 X를 fake라고 예측했다\n",
    "- D 입장 : 이런! 오차를 무한대로!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.training.adagrad.AdagradOptimizer"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# optimizer\n",
    "tf.train.MomentumOptimizer\n",
    "tf.train.AdagradOptimizer #현재로서는 아담이 제일 좋은 편. 보통 많이씀 근데 다른것도 써보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.02\n",
    "\n",
    "G, W_G = generator(Z)\n",
    "\n",
    "D_X, W_D = discriminator(X)\n",
    "D_G, W_D = discriminator(G)\n",
    "\n",
    "loss_D = -tf.reduce_mean(tf.log(D_X) + tf.log(1 - D_G))\n",
    "loss_G = -tf.reduce_mean(tf.log(D_G))\n",
    "\n",
    "train_D = tf.train.AdamOptimizer(learning_rate).minimize(loss_D, var_list=W_D)\n",
    "train_G = tf.train.AdamOptimizer(learning_rate).minimize(loss_G, var_list=W_G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_fig(pred, y, sample_size):\n",
    "    fig, ax = plt.subplots(2, sample_size, figsize=(sample_size, 2))\n",
    "\n",
    "    for i in range(sample_size):\n",
    "        ax[0][i].set_axis_off()\n",
    "        ax[1][i].set_axis_off()\n",
    "        ax[0][i].imshow(np.reshape(pred[i], (28, 28)))\n",
    "        ax[1][i].imshow(np.reshape(y[i], (28, 28)))\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoches=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 epoch......finished\n",
      "2 epoch......finished\n",
      "3 epoch......finished\n",
      "4 epoch......finished\n",
      "5 epoch......finished\n",
      "6 epoch......finished\n",
      "7 epoch......finished\n",
      "8 epoch......finished\n",
      "9 epoch......finished\n",
      "10 epoch......finished\n",
      "11 epoch......finished\n",
      "12 epoch......finished\n",
      "13 epoch......finished\n",
      "14 epoch......finished\n",
      "15 epoch......finished\n",
      "16 epoch......finished\n",
      "17 epoch......finished\n",
      "18 epoch......finished\n",
      "19 epoch......finished\n",
      "20 epoch......finished\n",
      "21 epoch......finished\n",
      "22 epoch......finished\n",
      "23 epoch......finished\n",
      "24 epoch......finished\n",
      "25 epoch......finished\n",
      "26 epoch......finished\n",
      "27 epoch......finished\n",
      "28 epoch......finished\n",
      "29 epoch......finished\n",
      "30 epoch......finished\n",
      "31 epoch......finished\n",
      "32 epoch......finished\n",
      "33 epoch......finished\n",
      "34 epoch......finished\n",
      "35 epoch......finished\n",
      "36 epoch......finished\n",
      "37 epoch......finished\n",
      "38 epoch......finished\n",
      "39 epoch......finished\n",
      "40 epoch......finished\n",
      "41 epoch......finished\n",
      "42 epoch......finished\n",
      "43 epoch......finished\n",
      "44 epoch......finished\n",
      "45 epoch......finished\n",
      "46 epoch......finished\n",
      "47 epoch......finished\n",
      "48 epoch......finished\n",
      "49 epoch......finished\n",
      "50 epoch......finished\n",
      "51 epoch......finished\n",
      "52 epoch......finished\n",
      "53 epoch......finished\n",
      "54 epoch......finished\n",
      "55 epoch......finished\n",
      "56 epoch......finished\n",
      "57 epoch......finished\n",
      "58 epoch......finished\n",
      "59 epoch......finished\n",
      "60 epoch......finished\n",
      "61 epoch......finished\n",
      "62 epoch......finished\n",
      "63 epoch......finished\n",
      "64 epoch......finished\n",
      "65 epoch......finished\n",
      "66 epoch......finished\n",
      "67 epoch......finished\n",
      "68 epoch......finished\n",
      "69 epoch......finished\n",
      "70 epoch......finished\n",
      "71 epoch......finished\n",
      "72 epoch......finished\n",
      "73 epoch......finished\n",
      "74 epoch......finished\n",
      "75 epoch......finished\n",
      "76 epoch......finished\n",
      "77 epoch......finished\n",
      "78 epoch......finished\n",
      "79 epoch......finished\n",
      "80 epoch......finished\n",
      "81 epoch......finished\n",
      "82 epoch......finished\n",
      "83 epoch......finished\n",
      "84 epoch......finished\n",
      "85 epoch......finished\n",
      "86 epoch......finished\n",
      "87 epoch......finished\n",
      "88 epoch......finished\n",
      "89 epoch......finished\n",
      "90 epoch......finished\n",
      "91 epoch......finished\n",
      "92 epoch......finished\n",
      "93 epoch......finished\n",
      "94 epoch......finished\n",
      "95 epoch......finished\n",
      "96 epoch......finished\n",
      "97 epoch......finished\n",
      "98 epoch......finished\n",
      "99 epoch......finished\n",
      "100 epoch......finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\finance\\lib\\site-packages\\matplotlib\\image.py:395: UserWarning: Warning: converting a masked element to nan.\n",
      "  dv = (np.float64(self.norm.vmax) -\n",
      "C:\\ProgramData\\Anaconda3\\envs\\finance\\lib\\site-packages\\matplotlib\\image.py:396: UserWarning: Warning: converting a masked element to nan.\n",
      "  np.float64(self.norm.vmin))\n",
      "C:\\ProgramData\\Anaconda3\\envs\\finance\\lib\\site-packages\\matplotlib\\image.py:403: UserWarning: Warning: converting a masked element to nan.\n",
      "  a_min = np.float64(newmin)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\finance\\lib\\site-packages\\matplotlib\\image.py:408: UserWarning: Warning: converting a masked element to nan.\n",
      "  a_max = np.float64(newmax)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\finance\\lib\\site-packages\\matplotlib\\colors.py:918: UserWarning: Warning: converting a masked element to nan.\n",
      "  dtype = np.min_scalar_type(value)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\finance\\lib\\site-packages\\numpy\\ma\\core.py:713: UserWarning: Warning: converting a masked element to nan.\n",
      "  data = np.array(a, copy=False, subok=subok)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x144 with 20 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    # ********* Training and Testing\n",
    "    noise_test = np.random.normal(size=(10, 128)) # 10 = Test Sample Size, 128 = Noise Dimension\n",
    "    \n",
    "    for epoch in range(epoches): # 200 = Num. of Epoch\n",
    "        print('{} epoch'.format(epoch+1), end='')\n",
    "        for i in range(int(mnist.train.num_examples / 100)): # 100 = Batch Size\n",
    "            batch_xs, _ = mnist.train.next_batch(100)\n",
    "            noise = np.random.normal(size=(100, 128)) #128자유롭게 주렴 \n",
    "\n",
    "            sess.run(train_D, feed_dict={X: batch_xs, Z: noise})\n",
    "            sess.run(train_G, feed_dict={Z: noise})\n",
    "            if i % 100 == 0:\n",
    "                print('.', end='')\n",
    "        print('finished')\n",
    "        \n",
    "    samples = sess.run(G, feed_dict={Z: noise_test})\n",
    "            \n",
    "    sample_size=10\n",
    "    print_fig(samples, mnist.test.images, sample_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
