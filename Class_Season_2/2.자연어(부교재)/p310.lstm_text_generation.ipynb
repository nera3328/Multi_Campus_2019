{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Activation, Dropout\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 세익스피어 소설을 읽는다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus length: 581432\n",
      "total chars: 61\n",
      "['\\n', ' ', '!', '\"', '#', '&', \"'\", '(', ')', '*', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '<', '>', '?', '@', '[', ']', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '|', '~']\n"
     ]
    }
   ],
   "source": [
    "text = open('shakespeare_final.txt').read().lower()\n",
    "print('corpus length:', len(text))\n",
    "\n",
    "characters = sorted(list(set(text)))\n",
    "print('total chars:', len(characters))\n",
    "print(characters) #문자 61개의 조합!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'\\n': 0, ' ': 1, '!': 2, '\"': 3, '#': 4, '&': 5, \"'\": 6, '(': 7, ')': 8, '*': 9, ',': 10, '-': 11, '.': 12, '/': 13, '0': 14, '1': 15, '2': 16, '3': 17, '4': 18, '5': 19, '6': 20, '7': 21, '8': 22, '9': 23, ':': 24, ';': 25, '<': 26, '>': 27, '?': 28, '@': 29, '[': 30, ']': 31, '_': 32, 'a': 33, 'b': 34, 'c': 35, 'd': 36, 'e': 37, 'f': 38, 'g': 39, 'h': 40, 'i': 41, 'j': 42, 'k': 43, 'l': 44, 'm': 45, 'n': 46, 'o': 47, 'p': 48, 'q': 49, 'r': 50, 's': 51, 't': 52, 'u': 53, 'v': 54, 'w': 55, 'x': 56, 'y': 57, 'z': 58, '|': 59, '~': 60}\n",
      "\n",
      "{0: '\\n', 1: ' ', 2: '!', 3: '\"', 4: '#', 5: '&', 6: \"'\", 7: '(', 8: ')', 9: '*', 10: ',', 11: '-', 12: '.', 13: '/', 14: '0', 15: '1', 16: '2', 17: '3', 18: '4', 19: '5', 20: '6', 21: '7', 22: '8', 23: '9', 24: ':', 25: ';', 26: '<', 27: '>', 28: '?', 29: '@', 30: '[', 31: ']', 32: '_', 33: 'a', 34: 'b', 35: 'c', 36: 'd', 37: 'e', 38: 'f', 39: 'g', 40: 'h', 41: 'i', 42: 'j', 43: 'k', 44: 'l', 45: 'm', 46: 'n', 47: 'o', 48: 'p', 49: 'q', 50: 'r', 51: 's', 52: 't', 53: 'u', 54: 'v', 55: 'w', 56: 'x', 57: 'y', 58: 'z', 59: '|', 60: '~'}\n"
     ]
    }
   ],
   "source": [
    "#문자에 대한 index 맵핑한 dictionary\n",
    "char2indices = dict((c, i) for i, c in enumerate(characters))# ㄱ\n",
    "indices2char = dict((i, c) for i, c in enumerate(characters))# 뒤집\n",
    "print(char2indices)\n",
    "print()\n",
    "print(indices2char)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cut the text in semi-redundant sequences of maxlen characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb sequences: 193798\n"
     ]
    }
   ],
   "source": [
    "#학습 데이터 구성\n",
    "maxlen = 40 #문자 수는 40개 sequence  씩 불러와서 x에 불러올거야 y는 그 다음 문자(next character)\n",
    "step = 3 #임의의 수, 3글자(character)점프하고 x값 40개씩\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(0, len(text) - maxlen, step): #사이즈 계산 -58만개에서 앞에서 40개 빼고, 뒤에서 40개 뺀 만큼, 앞의 3칸 건너 띄어서 40글자 뽑을 수 있도록!\n",
    "    sentences.append(text[i: i + maxlen])# 0 40개, 1 40개''씩을 x로 만들 수 있도록 만듦 \n",
    "    next_chars.append(text[i + maxlen])# y는 next chars\n",
    "print('nb sequences:', len(sentences)) #x,y는 19만개씩 쌓임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the project gutenberg ebook of the compl',\n",
       " ' project gutenberg ebook of the complete',\n",
       " 'oject gutenberg ebook of the complete wo',\n",
       " 'ct gutenberg ebook of the complete works',\n",
       " 'gutenberg ebook of the complete works of',\n",
       " 'enberg ebook of the complete works of wi',\n",
       " 'erg ebook of the complete works of willi',\n",
       " ' ebook of the complete works of william ',\n",
       " 'ook of the complete works of william sha',\n",
       " ' of the complete works of william shakes']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[:10] # x data 40개, --->LSTM box 40개씩 만들어서 다음 y가 e가 나오도록 학습(one-hot 형식으로)\n",
    "# 얘네 세로열로 나열, 열은 61개, ->out put 61개 나오도록해"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['e', ' ', 'r', ' ', ' ', 'l', 'a', 's', 'k', 'p']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_chars[:10] #y data= 61개, 입력도 61개로 맞추어주어야함(문자 수= one-hot 자리 값 수)--->one-hot 단계 필요"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting indices into vectorized format (one-hot 변환)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: '\\n', 1: ' ', 2: '!', 3: '\"', 4: '#', 5: '&', 6: \"'\", 7: '(', 8: ')', 9: '*', 10: ',', 11: '-', 12: '.', 13: '/', 14: '0', 15: '1', 16: '2', 17: '3', 18: '4', 19: '5', 20: '6', 21: '7', 22: '8', 23: '9', 24: ':', 25: ';', 26: '<', 27: '>', 28: '?', 29: '@', 30: '[', 31: ']', 32: '_', 33: 'a', 34: 'b', 35: 'c', 36: 'd', 37: 'e', 38: 'f', 39: 'g', 40: 'h', 41: 'i', 42: 'j', 43: 'k', 44: 'l', 45: 'm', 46: 'n', 47: 'o', 48: 'p', 49: 'q', 50: 'r', 51: 's', 52: 't', 53: 'u', 54: 'v', 55: 'w', 56: 'x', 57: 'y', 58: 'z', 59: '|', 60: '~'}\n"
     ]
    }
   ],
   "source": [
    "# 계획단계\n",
    "X = np.zeros((len(sentences), maxlen, len(characters)), dtype=np.bool)\n",
    "#         (data(batch) 개수,  40(time_step), lstm input feature 개수)---->lstm 만들려면 3차원 구조 필요!\n",
    "y = np.zeros((len(sentences), len(characters)), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences): #sentence는 x로 가져오는 한 줄\n",
    "    for t, char in enumerate(sentence):\n",
    "        X[i, t, char2indices[char]] = 1\n",
    "      # i:면, t:행    ㄴ 열(15)\n",
    "    y[i, char2indices[next_chars[i]]] = 1\n",
    "print(indices2char)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNN에 넣을 학습 data 완성!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 128)               97280     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 61)                7869      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 61)                0         \n",
      "=================================================================\n",
      "Total params: 105,149\n",
      "Trainable params: 105,149\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()#keras 사용!\n",
    "model.add(LSTM(128, input_shape=(maxlen, len(characters))))\n",
    "#각 box에서 나오는 것은 128개(출력)/timestep=40,   61개\n",
    "model.add(Dense(len(characters))) #층 추가\n",
    "#                    61개 output 나오도록 ㄱ\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(lr=0.01))\n",
    "\n",
    "print (model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to convert prediction into index\n",
    "[0.4, 0.6]을 아래 함수로 변환하면 ...<br>\n",
    "1. metric = 1.0 이면 [0.4, 0.6] - 불변\n",
    "2. metric = 0.2 이면 [0.17, 0.83] - 차이가 더 커짐\n",
    "3. metric = 1.5 이면 [0.43, 0.57] - 차이가 작아짐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 5 3]\n",
      "[1 5 3]\n"
     ]
    }
   ],
   "source": [
    "#asarray와 array의 차이!\n",
    "\n",
    "a=np.array([1,2,3])\n",
    "b=np.asarray(a)\n",
    "b[1]=5\n",
    "print(b)\n",
    "print(a)#--------> 두 관계는 연결되어있다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3]\n",
      "[1 4 3]\n"
     ]
    }
   ],
   "source": [
    "c=np.array([1,2,3])\n",
    "d=np.array(c)\n",
    "d[1]=4\n",
    "print(c)\n",
    "print(d)#------>분리되어있따"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 61개 softmax vector를 word index로 변환한다. (주사위를 써서 확률적으로 변환)\n",
    "def pred_indices(preds, metric = 1.0):# mertric: soft max의 B값, 1.0은 초기값\n",
    "    preds = np.asarray(preds).astype('float64')#필수 문장은 아님\n",
    "                                              # = preds=preds.dtype('float64')가 더 낫다\n",
    "    preds = np.log(preds) / metric\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds/np.sum(exp_preds)\n",
    "    probs = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probs)\n",
    "# B를 적용한 softmax 결과"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train & Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/1\n",
      "193798/193798 [==============================] - 80s 414us/step - loss: 1.9099\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xf2f8e48>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, batch_size = 128, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 문장 1개를 선택하고 이후에 나타날 문자 1개를 예측한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'y\\nservice that charges for download time'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 임의 문장 1개를 선택한다\n",
    "start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "#                                ㄴ      40       _ㅣ\n",
    "sentence = text[start_index: start_index + maxlen]\n",
    "sentence# 40글자! 선택된 문장, e 다음 나올 문자는?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "o\n"
     ]
    }
   ],
   "source": [
    "# 선택한 문장 다음에 나올 단어를 예측해 본다.\n",
    "x = np.zeros((1, maxlen, len(characters))) (1, 40, 61) # x처럼 shape는 3D 구조\n",
    "for t, char in enumerate(sentence):\n",
    "    x[0, t, char2indices[char]] = 1.    # 문자 특정 지점만 1로 해서 LSTM에 밀어넣음\n",
    "\n",
    "preds = model.predict(x, verbose=0)[0]  # 다음 철자 예측 (61개 짜리 one-hot값, softmax)\n",
    "#       다음 단어의 one-hot vector 예측, Y_hat은 실제론 실수 (0.1,0.3'')값으로 나옴 근데 너무 정적이라서 \n",
    "next_index = pred_indices(preds, 0.2) #다음 철자의 숫자(딕션에서 정의된 단어 순서) / ㄴ0.2는 함수정의,사용, B\n",
    "pred_char = indices2char[next_index]#철자 자체\n",
    "print(pred_char) #61개의 one-hot을 다시 voca로 바꾸면?-->o (예측)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 문장 1개를 선택하고 이후에 나타날 문자 400개를 연속으로 예측한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Generating with seed: \"  nor taste, nor smell, desire to be inv\"\n",
      "\n",
      "ertents to the stands with the stand the stands to the world the harts the stands,\n",
      "    and the stand to the stand the searent,\n",
      "    that i will not the stand the world the graise,\n",
      "    the world the wast the seed to and the storther,\n",
      "    the stand the beartent of the stand the stand the way,\n",
      "    and the self the stand the stand the stand the startent,\n",
      "    the stand the stand the stand the world in t"
     ]
    }
   ],
   "source": [
    "# 임의 문장 1개를 선택한다\n",
    "start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "sentence = text[start_index: start_index + maxlen]\n",
    "\n",
    "generated = ''\n",
    "generated += sentence\n",
    "print('----- Generating with seed: \"' + sentence + '\"\\n')\n",
    "\n",
    "diversity = 0.2\n",
    "for i in range(400):\n",
    "    x = np.zeros((1, maxlen, len(characters)))\n",
    "    for t, char in enumerate(sentence):\n",
    "        x[0, t, char2indices[char]] = 1.    # 문장\n",
    "\n",
    "    preds = model.predict(x, verbose=0)[0]  \n",
    "    next_index = pred_indices(preds, diversity) \n",
    "    pred_char = indices2char[next_index]\n",
    "\n",
    "    generated += pred_char\n",
    "    sentence = sentence[1:] + pred_char\n",
    "\n",
    "    print(pred_char, end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 원래 책에 있는 소스 프로그램\n",
    "iteration이 증가할수록 (학습량이 증가할수록) 생성된 문장의 품질을 비교해 보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Iteration 1\n",
      "WARNING:tensorflow:From C:\\Users\\seong\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/1\n",
      "193798/193798 [==============================] - 111s 574us/step - loss: 1.9245\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \" wife,\n",
      "  the world will be thy widow and\"\n",
      " wife,\n",
      "  the world will be thy widow and the world the foor and the world the world the part the read\n",
      "    the commessend the world the some the mostle and the prosisers and the world so sure the world my may the thement the world my mostlespeare the thee,\n",
      "    the world the send the comes to messarant\n",
      "    the restress and the women the world the commended to myselveres\n",
      "    which the make world the world the world the proselt your marrand\n",
      "One combination completed \n",
      "\n",
      "\n",
      "----- diversity: 0.7\n",
      "----- Generating with seed: \" wife,\n",
      "  the world will be thy widow and\"\n",
      " wife,\n",
      "  the world will be thy widow and portant\n",
      "  dutter. ender ard worth not a prose show hearerrain time\n",
      "    a to most uresarain your oundicervion shall by the seiver\n",
      "    the had the greadediand i but the hast,\n",
      "    out when then myselvion parous and poaticensers\n",
      "    there that will merating, which my to may buther adicertion the disture,\n",
      "    the wollding you her it mostresparanl and my master\n",
      "    if my some i have sompesared i's worl\n",
      "One combination completed \n",
      "\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \" wife,\n",
      "  the world will be thy widow and\"\n",
      " wife,\n",
      "  the world will be thy widow and so wovichotiless proking,ule loit\n",
      "ch, i camesflave.  you belreson the do-peediered. aves whoul\n",
      "    and in spey it,\n",
      "  a dowall weat varrfuach wored dilacktoered go mecuro'shds what have to mancer's?\n",
      "\n",
      "\n",
      "\n",
      "schares-shatl me lovens of ghest\n",
      "    ind, have thy mosoppal.\n",
      "    first so aimtnenoth, where thriser out\n",
      "    thes wose butknetiepsteck?\n",
      "  jomes'd. wake duck, 'termest carcli.\n",
      "  curwas.. if hith is th\n",
      "One combination completed \n",
      "\n",
      "----------------------------------------\n",
      "Iteration 2\n",
      "Epoch 1/1\n",
      " 11520/193798 [>.............................] - ETA: 1:48 - loss: 1.5949"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-566faac81a94>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'-'\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m40\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Iteration'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mstart_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mmaxlen\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for iteration in range(1, 30):\n",
    "    print('-' * 40)\n",
    "    print('Iteration', iteration)\n",
    "    \n",
    "    # 반복할 때마다 계속 학습함.\n",
    "    model.fit(X, y, batch_size = 128, epochs=1)\n",
    "\n",
    "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "\n",
    "    for diversity in [0.2, 0.7, 1.2]:\n",
    "\n",
    "        print('\\n----- diversity:', diversity)\n",
    "        #                            B\n",
    "        generated = ''\n",
    "        sentence = text[start_index: start_index + maxlen]\n",
    "        generated += sentence\n",
    "        print('----- Generating with seed: \"' + sentence + '\"')\n",
    "        sys.stdout.write(generated)\n",
    "\n",
    "        for i in range(400):\n",
    "            x = np.zeros((1, maxlen, len(characters)))\n",
    "            for t, char in enumerate(sentence):\n",
    "                x[0, t, char2indices[char]] = 1.\n",
    "\n",
    "            preds = model.predict(x, verbose=0)[0]\n",
    "            next_index = pred_indices(preds, diversity)\n",
    "            pred_char = indices2char[next_index]\n",
    "\n",
    "            generated += pred_char\n",
    "            sentence = sentence[1:] + pred_char\n",
    "\n",
    "            sys.stdout.write(pred_char)\n",
    "            sys.stdout.flush()\n",
    "        print(\"\\nOne combination completed \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
